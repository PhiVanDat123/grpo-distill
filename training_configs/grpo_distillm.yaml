# GRPO + DistiLLM-v2 Training Configuration
# 
# This config trains a student model using:
# - GRPO for RL-based policy optimization with group-relative advantages
# - DistiLLM-v2 for knowledge distillation from teacher
#
# Usage: python run_grpo_distillm.py grpo_distillm_config.yaml

# Model Configuration
model_name_or_path: Qwen/Qwen2.5-Math-1.5B-Instruct  # Student model (to be trained)
ref_model_name_or_path: Qwen/Qwen2.5-Math-7B-Instruct  # Teacher model (frozen, for distillation)
torch_dtype: bfloat16
attn_implementation: null
trust_remote_code: true

# PEFT/LoRA Configuration (optional - comment out if not using)
use_peft: true
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
lora_target_modules:
  - q_proj
  - k_proj
  - v_proj
  - o_proj
  - gate_proj
  - up_proj
  - down_proj

# Dataset Configuration
dataset_mixer:
  VoCuc/MetaMathQA-50k-256: 1.0
dataset_splits:
  - train
preprocessing_num_workers: 8

# GRPO Hyperparameters
num_samples_per_prompt: 4  # G - number of responses per prompt
clip_epsilon: 0.2  # PPO clipping parameter ε
beta: 0.1  # Weight for DistiLLM-v2 loss
old_policy_update_frequency: 50  # Update π_θ_old every N steps

# DistiLLM-v2 Hyperparameters
base_alpha_1: 0.1  # Alpha for forward KL (teacher -> mixture)
base_alpha_2: 0.1  # Alpha for reverse KL (student -> mixture)

# Generation Parameters
max_length: 1024
max_prompt_length: 256
max_new_tokens: 512
temperature: 0.7
top_p: 0.9

# Training Configuration
output_dir: outputs/grpo-distillm-qwen2.5-1.5b
num_train_epochs: 1
per_device_train_batch_size: 2  # Effective batch = this * num_samples_per_prompt * gradient_accumulation
per_device_eval_batch_size: 2
gradient_accumulation_steps: 8
gradient_checkpointing: true
learning_rate: 5.0e-6
lr_scheduler_type: cosine
warmup_ratio: 0.1
weight_decay: 0.01
max_grad_norm: 1.0

# Optimizer
optim: adamw_torch

# Logging & Saving
logging_steps: 10
save_steps: 500
eval_steps: 500
save_total_limit: 3
logging_first_step: true

# Evaluation
do_eval: true
evaluation_strategy: steps

# Misc
seed: 42
bf16: true
remove_unused_columns: false
dataloader_num_workers: 4
disable_dropout: true
label_pad_token_id: -100

# Hub (optional)
push_to_hub: false
# hub_model_id: your-username/grpo-distillm-model